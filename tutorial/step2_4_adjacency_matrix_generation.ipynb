{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Adjacency Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DOLPHIN import combine_adj,combine_adj_comp, adj_comp_re_part1, adj_comp_re_part2, adj_comp_re_part3,get_adj_hvg\n",
    "# #miss one \"step02_adj_mat_main_part2_main_2_parallel_run_X\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = \"your_metaData.csv\"\n",
    "df_label = pd.read_csv(metadata, sep='\\t')\n",
    "total_sample_size = len(df_label)\n",
    "\n",
    "# Define your study name (update this for your specific study)\n",
    "study_name = \"STUDY\"\n",
    "\n",
    "adj_run_num = 100\n",
    "\n",
    "output_directory = os.path.join(main_folder, \"final_data\")\n",
    "graph_directory = os.path.join(main_folder \"06_graph_mtx\")\n",
    "exon_gene_featurecount_directory=os.path.join(main_folder, \"04_exon_gene_cnt\")\n",
    "\n",
    "# Required files\n",
    "gene_annotation = \"gene_id_annotation.csv\"\n",
    "gtf_pkl_path = \"gtf.pkl\"\n",
    "gtf_jun_pkl_path = \"df_jun_gtf.pkl\"\n",
    "gtf_path= \"Homo_sapiens.GRCh38.107.gtf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine all Adjacency Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Start Combine Adjacency Matrix\")\n",
    "with tqdm(total=total_sample_size) as pbar_adj:\n",
    "    for i in range(0, total_sample_size):\n",
    "        if i%adj_run_num==0:\n",
    "            pbar_adj=combine_adj(pbar_adj, df_label, graph_directory, gtf_jun_pkl_path, start_idx = i, sample_num=adj_run_num, output_path=output_directory, output_name= study_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### combine all adjacency .h5ad files\n",
    "total_number_adj_anndata = math.ceil(total_sample_size/adj_run_num)\n",
    "_anndata_adj_dict = {}\n",
    "_aa_all_names_lst = []\n",
    "for j in range(0, total_number_adj_anndata):\n",
    "    print(j)\n",
    "    _temp_ad = anndata.read_h5ad(os.path.join(output_directory, \"Adjacency_\"+study_name+\"_\"+str(j)+\".h5ad\"))\n",
    "    _anndata_adj_dict[\"AA\"+str(j%5)] = _temp_ad\n",
    "\n",
    "    if j < (len(range(0, total_number_adj_anndata)) // 5) * 5:\n",
    "        if (j+1)%5 == 0:\n",
    "            for _i, (_, _ad) in enumerate(_anndata_adj_dict.items()):\n",
    "                if _i == 0:\n",
    "                    combine_anndata_adj = _ad\n",
    "                else:\n",
    "                    combine_anndata_adj = combine_anndata_adj.concatenate(_ad, index_unique = None, batch_key = None)\n",
    "            _out_aa_name = \"Adjacency_\"+study_name+\"_\"+str(j-4)+\"_\"+str(j)+\".h5ad\"\n",
    "            combine_anndata_adj.write(os.path.join(output_directory,_out_aa_name))\n",
    "            _anndata_adj_dict = {}\n",
    "            _aa_all_names_lst.append(_out_aa_name)\n",
    "    elif j>=(len(range(0, total_number_adj_anndata)) // 5) * 5 and j==max(range(0, total_number_adj_anndata)):\n",
    "        for _i, (_, _ad) in enumerate(_anndata_adj_dict.items()):\n",
    "            if _i == 0:\n",
    "                combine_anndata_adj = _ad\n",
    "            else:\n",
    "                combine_anndata_adj = combine_anndata_adj.concatenate(_ad, index_unique = None, batch_key = None)\n",
    "        _out_aa_name = \"Adjacency_\"+study_name+\"_\"+str(total_number_adj_anndata%5+1)+\"_\"+str(j)+\".h5ad\" \n",
    "        combine_anndata_adj.write(os.path.join(output_directory, _out_aa_name))\n",
    "        _anndata_adj_dict = {}\n",
    "        _aa_all_names_lst.append(_out_aa_name)\n",
    "\n",
    "print(_aa_all_names_lst)\n",
    "_anndata_aa_all_dict = {}\n",
    "for _i, _ca_name in enumerate(_aa_all_names_lst):\n",
    "    _temp_ad = anndata.read_h5ad(os.path.join(output_directory, _ca_name))\n",
    "    _anndata_aa_all_dict[\"AA_all\"+str(_i)] = _temp_ad\n",
    "    for _i, (_, _ad) in enumerate(_anndata_aa_all_dict.items()):\n",
    "        if _i == 0:\n",
    "            combine_anndata = _ad\n",
    "        else:\n",
    "            combine_anndata = combine_anndata.concatenate(_ad, index_unique = None, batch_key = None)\n",
    "    combine_anndata.write(os.path.join(output_directory,\"Adjacency_\"+study_name+\".h5ad\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Remove All Temporary Datasets\n",
    "file_pattern = os.path.join(output_directory, f\"Adjacency_{study_name}_*\")\n",
    "\n",
    "files_to_remove = glob.glob(file_pattern)\n",
    "\n",
    "# Remove each file\n",
    "for file in files_to_remove:\n",
    "    if os.path.exists(file):  # Check if the file exists\n",
    "        os.remove(file)\n",
    "        print(f\"Removed: {file}\")\n",
    "    else:\n",
    "        print(f\"File not found: {file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Junction to 0 if Both Exon Counts are Zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate compressed version adjacency matrix\n",
    "print(\"Start Generating Compressed version of Adjacency Matrix\")\n",
    "with tqdm(total=total_sample_size) as pbar:\n",
    "    for i in range(0, total_sample_size):\n",
    "        if i%adj_run_num==0:\n",
    "            pbar=combine_adj_comp(pbar, df_label, start_idx = i, sample_num=adj_run_num, output_path=output_directory, output_name= study_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### combine the compressed adjacency matrix\n",
    "_anndata_ca_dict = {}\n",
    "\n",
    "total_number_anndata = math.ceil(total_sample_size/adj_run_num)\n",
    "_ca_all_names_lst = []\n",
    "print(\"Combining \", total_number_anndata, \" compressed adjacency anndata\")\n",
    "for j in range(0, total_number_anndata):\n",
    "    print(j)\n",
    "    _temp_ad = anndata.read_h5ad(os.path.join(output_directory, \"AdjacencyComp_\"+study_name+\"_\"+str(j)+\".h5ad\"))\n",
    "    _anndata_ca_dict[\"CA\"+str(j%5)] = _temp_ad\n",
    "\n",
    "    if j < (len(range(0, total_number_anndata)) // 5) * 5:\n",
    "        if (j+1)%5 == 0:\n",
    "            for _i, (_, _ad) in enumerate(_anndata_ca_dict.items()):\n",
    "                if _i == 0:\n",
    "                    combine_anndata = _ad\n",
    "                else:\n",
    "                    combine_anndata = combine_anndata.concatenate(_ad, index_unique = None, batch_key = None)\n",
    "            _out_ca_name = \"AdjacencyComp_\"+study_name+\"_\"+str(j-4)+\"_\"+str(j)+\".h5ad\"\n",
    "            combine_anndata.write(os.path.join(output_directory,_out_ca_name))\n",
    "            _anndata_ca_dict = {}\n",
    "            _ca_all_names_lst.append(_out_ca_name)\n",
    "    elif j>=(len(range(0, total_number_anndata)) // 5) * 5 and j==max(range(0, total_number_anndata)):\n",
    "        for _i, (_, _ad) in enumerate(_anndata_ca_dict.items()):\n",
    "            if _i == 0:\n",
    "                combine_anndata = _ad\n",
    "            else:\n",
    "                combine_anndata = combine_anndata.concatenate(_ad, index_unique = None, batch_key = None)\n",
    "        _out_ca_name = \"AdjacencyComp_\"+study_name+\"_\"+str(total_number_anndata%5+1)+\"_\"+str(j)+\".h5ad\" \n",
    "        combine_anndata.write(os.path.join(output_directory, _out_ca_name))\n",
    "        _anndata_ca_dict = {}\n",
    "        _ca_all_names_lst.append(_out_ca_name)\n",
    "\n",
    "_anndata_ca_all_dict = {}\n",
    "for _i, _ca_name in enumerate(_ca_all_names_lst):\n",
    "    _temp_ad = anndata.read_h5ad(os.path.join(output_directory, _ca_name))\n",
    "    _anndata_ca_all_dict[\"CA_all\"+str(_i)] = _temp_ad\n",
    "    for _i, (_, _ad) in enumerate(_anndata_ca_all_dict.items()):\n",
    "        if _i == 0:\n",
    "            combine_anndata = _ad\n",
    "        else:\n",
    "            combine_anndata = combine_anndata.concatenate(_ad, index_unique = None, batch_key = None)\n",
    "    combine_anndata.write(os.path.join(output_directory,\"AdjacencyComp_\"+study_name+\".h5ad\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Remove All Temporary Datasets\n",
    "file_pattern = os.path.join(output_directory, f\"AdjacencyComp_{study_name}_*\")\n",
    "\n",
    "files_to_remove = glob.glob(file_pattern)\n",
    "\n",
    "# Remove each file\n",
    "for file in files_to_remove:\n",
    "    if os.path.exists(file):  # Check if the file exists\n",
    "        os.remove(file)\n",
    "        print(f\"Removed: {file}\")\n",
    "    else:\n",
    "        print(f\"File not found: {file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Junctions if All Cells Have a Count of Zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_comp_re_part1(output_directory, study_name)\n",
    "adj_comp_re_part2(output_directory, study_name)\n",
    "adj_comp_re_part3(output_directory, study_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Adjacency Matrix with Highly Variable Genes (HVG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_adj_hvg(output_directory, study_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DOLPHIN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
